# Aurover

## Overview
Aurover is currently just the culmination of a few thoughts I had today. I was working on an approximate solution to the traveling salesperson problem, inspired by a [simulation][ants] I saw from Sebastian Lague which generated an approximate solution stochastically by adapting a metaphor from nature: It likened the problem to that of efficiently visiting sites in an ant colony, aided in navigation only by pheromone trails of preceding ants. My thoughts immediately went to the music that I was listening to in the background, because this is something of a curiosity for me recently: I have a list of tracks that I keep revisiting, and I like curating selections from my library of music to listen to depending on my mood. But what's the "optimal" ordering of the tracks in my "set?" My hope is to use topology to explore that problem space by formulating it as a variant of the famous traveling salesperson problem. 

## Research and Scope
So, I went and looked to see if anyone else had done something similar, and I bumped almost immediately into [Robert Dargavel Smith's MBIT Master's thesis][thesis], which critiqued prior automated deejaying software, citing that it merely made use of meta-data to mix tracks into a single stream, which he and I both found intuitively uncompelling. Put concisely, and to quote Robert's excellent work, a good set is "not about how you play, but _what_ you play," and a single, long audio stream that sounds organically mixed together given a fixed set of tracks in a specific order is to be desired: But once audio has been reduced to this format, it isn't the most interesting from a topological perspective, and a one-shot solution to this problem can already be described by just fading out of one track and into another.

Instead, curating the tracks and presenting them in an order that makes them feel as though one is listening to the work of a single composer, and they're telling you a story or taking you on a tour in discrete acts instead of being presented a disparate mishmash of different compositional and instrumentational styles with no discernible ordering, is the true challenge. Can a synthetic "set" be constructed which sounds like a human constructed it to pass through minimal genre boundaries while visiting each, given only fingerprints derived from the audio itself? 

These are interesting questions, and now I'm excited to get started. So I've decided I wanted to do a variation on Robert's theme, but like him, I _also_ decided I'd declare it an explicit non-goal to mix tracks together, to keep my project scope somewhat more tractable, and because I think that unsupervised machine learning to _generate transitions_ between tracks would likely require a deeper insight into their compositional structure in the training data, e.g. [MusicNet] annotations, and I didn't want to get bogged down in trying to teach a computer to use those features for making music. Tool-assisted or unsupervised music generation for interstitial transitions between tracks is certainly an interesting problem, and one I could consider approaching in the future, but for now it can be a job for Elon Musk and company over at [OpenAI][jukebox].

# Methods
## Feature extraction
The first thing that jumped out at me in Robert's thesis was the use of Doc2Vec on raw audio for feature extraction from the unstructured music data in the _complete_ absence of meta-data, which seemed charming, and exotic, and very compelling. I decided I wanted, similarly, to train a model which encoded an understanding of why music "sounds" like other music, without any use of supervised annotations or other meta-data about the inputs in the final inference process, and that I would do it, like him, using Mel spectrograms generated with [librosa]'s [feature extraction routines][librosafx] as applied to [the Free Music archive][fma], leading to a machine-readable representation of how the human ear responds to audio which can be generated without supervision. At Google, CNNs have been employed in transfer learning tasks to a similar tune, where similar methods demonstrate an ability to perform short-term "physics-free" weather forecasting by analyzing meteorological visualizations intended for human viewers, as described in this [Singularity Hub article][shubweather].
 
I don't find myself particularly interested in inducing inference based on the graph of songs or tuning my results on that basis, I just want my AI to act based on the track's appearance in the latent feature-space induced by attempting that inference. So, I decided that one of the things I want to do differently from Robert is fine-tune a convolutional neural network for extraction of latent features from each song in lieu of using Doc2Vec or tf-idf on raw audio samples. Luckily, Google has a [Colaboratory notebook][notebook] where they demonstrate using Keras on one of their preemptible virtual learning environments to fine-tune [EfficientNet][efficientnet], which you can use free of charge, with full access to their hardware aside from the occasional interruption or AFK timeout, including compute-specialized GPUs from NVidia and ASICs developed at Google to process the large, dense tensors so common in deep learning.

While training a TensorFlow model is highly compute-intensive, it's much less so to freeze its parameters and make inferences based on new inputs. Still, one potential challenge is whether it's computationally tractable to do this for enough songs to generate a good solution space for pathfinding. If I run into problems, I might need to use some cheaper feature extraction technique for embedding songs than to simply run spectrograms of a massive amount of them through a CNN and embed each track as a vector lifted out of the model's penultimate layer for clustering as a synthetic solution space, which leads me to present an alternative problem formulation based on a pre-selected set of tracks; that of traveling salespeople. Each formulation is described in greater detail below.

## Pathfinding
The manner in which Robert stated the problem of track selection was this: Given an origin, a destination, and a desired set of intermediate stops, can a computer find a good series of discrete steps to get from point Q to point P? That sounded to me an awful lot like another well-known discrete optimization problem, the more generalized problem of finding the optimal way to connect discrete nodes, also known as [pathfinding]. We can treat the problem of making a "good" playlist as a pathfinding problem with a synthetic solution space generated using simple rules, e.g. "a destination node is to be treated as 'traversible' from a given origin iff. the cosine of their respective embeddings is greater than 0.5." By clustering dense audio embeddings and applying a minimum bound to a matrix of their affinities, one can generate a solution space of valid "neighbors" for each node. My hope is that running search algorithms such as the greedy algorithm or Djikstra's algorithm on the result would produce a series of tracks that appeared to journey from one point to another. For more inspiration I'll be looking to [Scikit-Learn][sklearn]'s [clustering] overview.

## TSP
My alternative to the above formulation, that of a pathfinding problem with a synthetic solution space, is to simply select candidate nodes beforehand and treat it as a traveling salesperson problem, bringing us full circle, and back to that [funny little video about ants][ants]. Importantly given my limited computational resources, pre-selected candidates consider only the embeddings of those tracks originally selected as candidates for inclusion in the final output. This video is very intuitive, and nice as a reference, but isn't very precise, so I also find it helpful to refer to papers like this one from [Kan Jun-man and Zhang Yi][antspaper]. I find approaching the problem this way very elegant: The power of metaphor as an abstractive and problem-solving tool can't really be reified any more concretely than just lifting solutions out of nature and applying them to novel problem domains.

Ant colony solutions to the traveling salesperson problem, however, have the distinct disadvantages of requiring extensive hyperparameter tuning against the colony system for each solution space, and of producing nondeterministic outputs which only converge with significant runtime, even given a simple problem. However, these can also be viewed as opportunities for customization, given an end-user who just wants to listen to an interesting playlist. Using a discrete optimizer to try to find the best hyperparameters in an interactive search, and produce the "best-sounding" playlist for any given set of tracks would be an interesting exercise, as would exploring the candidate solutions it produced in a kind of self-referential, biased random walk. However, as an alternative, I'll also be referring to [this paper from Ali Jazayeri and Hiroki Sayama][deterministic-tsp], which claims to describe a solution that runs in quadratic time over the number of input vertices, and produces deterministic output by conducting a one-shot hyperparameter search for any given input on the fly, eliminating the need for the optimizer's domain model to encode _a priori_ knowledge of the inputs.

[ants]: https://youtu.be/X-iSQQgOd1A?t=335s
[antspaper]: https://core.ac.uk/download/pdf/82731771.pdf
[thesis]: https://towardsdatascience.com/create-automatic-playlists-by-using-deep-learning-to-listen-to-the-music-b72836c24ce2
[algoriddim]: https://algoriddim.com
[librosa]: https://librosa.org/
[librosafx]: https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html?highlight=mel%20spectrogram#librosa.feature.melspectrogram
[shubweather]: https://singularityhub.com/2020/01/15/how-googles-new-weather-ai-makes-instant-accurate-forecasts/
[musicnet]: https://homes.cs.washington.edu/~thickstn/musicnet.html
[jukebox]: https://openai.com/blog/jukebox/
[pathfinding]: https://www.wikipedia.org/wiki/Pathfinding
[efficientnet]: https://arxiv.org/pdf/1905.11946.pdf%E5%A4%8D%E5%90%88%E6%A8%A1%E5%9E%8B%E7%BC%A9%E6%94%BE
[notebook]: https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/image_classification_efficientnet_fine_tuning.ipynb
[deterministic-tsp]: https://arxiv.org/ftp/arxiv/papers/1608/1608.01716.pdf
[sklearn]: https://scikit-learn.org/stable/
[clustering]: https://scikit-learn.org/stable/modules/clustering.html
[fma]: https://github.com/mdeff/fma